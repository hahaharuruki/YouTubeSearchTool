import faiss
import numpy as np
import json
from transformers import AutoTokenizer, AutoModel
import torch
import sys
from rank_bm25 import BM25Okapi
from typing import List, Dict, Tuple

def embed_query(text: str) -> np.ndarray:
    """ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã™ã‚‹"""
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®åˆæœŸåŒ–
    tokenizer = AutoTokenizer.from_pretrained("BAAI/bge-large-en-v1.5")
    model = AutoModel.from_pretrained("BAAI/bge-large-en-v1.5").to(device)
    
    # ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        max_length=512,
        padding=True
    ).to(device)
    
    # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    with torch.no_grad():
        outputs = model(**inputs)
        embedding = outputs.last_hidden_state[:, 0].cpu().numpy()
    
    return embedding.astype("float32")

def format_time(seconds: float) -> str:
    """ç§’æ•°ã‚’ MM:SS å½¢å¼ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    m = int(seconds // 60)
    s = int(seconds % 60)
    return f"{m:02d}:{s:02d}"

def hybrid_search(query: str, index: faiss.Index, metadata: List[Dict], top_k: int = 5) -> List[int]:
    """ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’å®Ÿè¡Œ"""
    print("ğŸ” æ¤œç´¢å®Ÿè¡Œä¸­...")
    
    # ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢
    query_vec = embed_query(query)
    D, I = index.search(query_vec.reshape(1, -1), top_k * 2)
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
    corpus = [doc["text"] for doc in metadata]
    bm25 = BM25Okapi(corpus)
    bm25_scores = bm25.get_scores(query.split())
    
    # ã‚¹ã‚³ã‚¢ã®çµ„ã¿åˆã‚ã›
    combined_scores = {}
    
    # FAISSã®çµæœã‚’å‡¦ç†
    for i, idx in enumerate(I[0]):
        if idx >= 0 and idx < len(metadata):
            combined_scores[idx] = 1.0 / (1 + D[0][i])
    
    # BM25ã®ã‚¹ã‚³ã‚¢ã‚’è¿½åŠ 
    for idx, score in enumerate(bm25_scores):
        if idx in combined_scores:
            combined_scores[idx] += score * 0.5  # BM25ã®ã‚¹ã‚³ã‚¢ã«é‡ã¿ä»˜ã‘
    
    # çµæœã®ã‚½ãƒ¼ãƒˆ
    sorted_results = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)
    return [idx for idx, _ in sorted_results[:top_k]]

def main():
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®ãƒã‚§ãƒƒã‚¯
    if len(sys.argv) < 3:
        print("ä½¿ã„æ–¹: python search_cli.py <YouTubeã®URL> <æ¤œç´¢ã‚¯ã‚¨ãƒª>")
        sys.exit(1)

    youtube_url = sys.argv[1]
    query = sys.argv[2]

    try:
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        print("ğŸ“‚ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        index = faiss.read_index("faiss.index")
        with open("metadata.json", "r", encoding="utf-8") as f:
            metadata = json.load(f)

        # æ¤œç´¢ã®å®Ÿè¡Œ
        results = hybrid_search(query, index, metadata)

        # çµæœã®è¡¨ç¤º
        print("\nğŸ¯ æ¤œç´¢çµæœ:")
        for idx in results:
            if idx < 0 or idx >= len(metadata):
                continue
            
            seg = metadata[idx]
            start_sec = seg["start"]
            end_sec = seg["end"]
            text = seg["text"]
            start_fmt = format_time(start_sec)
            end_fmt = format_time(end_sec)
            link = f"{youtube_url}&t={int(start_sec)}s"
            
            print(f"\n[{start_fmt} - {end_fmt}] {text}")
            if "context" in seg:
                print(f"ğŸ“ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {seg['context']}")
            print(f"ğŸ”— {link}\n")

    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    main() 